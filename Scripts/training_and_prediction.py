# -*- coding: utf-8 -*-
"""GDB13_28__HOMO_LUMO1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w9OxJXDd2YTTgFobgXcykD_CeAfXHjJx

#Installation Packages
"""

#!pip install rdkit-pypi
#!pip install lazypredict
#!pip install catboost
#!pip install optuna
#!pip install lightgbm
#!pip install tensorflow

import warnings
warnings.filterwarnings("ignore")

from rdkit.Chem import AllChem
from rdkit import Chem
from rdkit.Chem import Descriptors
from rdkit.ML.Descriptors import MoleculeDescriptors
from rdkit.Chem import Draw
#from rdkit.Chem.Draw import IPythonConsole

import pandas as pd
import numpy as np

from sklearn.model_selection import cross_val_score,train_test_split
from sklearn.metrics import r2_score,mean_absolute_error, mean_squared_error
from sklearn.preprocessing import StandardScaler

#from matplotlib import pyplot as plt
#import matplotlib.patches as mpatches
#import seaborn as sn

#declare a folder name as variable
fd="GDB13_28"

# Load the CSV file
data_file = f"{fd}/GDB13_28_withidx.csv"
df = pd.read_csv(data_file)

new_data=df[['smiles','homolumogap']]

new_data

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Set font to Nimbus Sans and make it bold
#plt.rcParams['font.family'] = 'Nimbus Sans'
plt.rcParams['font.weight'] = 'bold'

# Load the CSV file
#file_path = '/content/your_file.csv'  # Replace with your uploaded file path
#data = pd.read_csv(file_path)

# Extract the homolumogap column
homolumogap = new_data['homolumogap']  # Replace with the actual column name if different

# Create bins for the histogram (rounded to nearest integers)
bin_edges = np.arange(homolumogap.min() // 1, homolumogap.max() // 1 + 2)  # Bin edges as integers
bin_counts, _ = np.histogram(homolumogap, bins=bin_edges)

# Plot the histogram
plt.figure(figsize=(12, 6))
bars = plt.hist(homolumogap, bins=bin_edges, edgecolor='black', color='skyblue', rwidth=1.0)

# Add counts on top of each bar
for count, edge_left, edge_right in zip(bin_counts, bin_edges[:-1], bin_edges[1:]):
    plt.text((edge_left + edge_right) / 2, count + 1,
             str(count), ha='center', va='bottom', fontsize=12, fontweight='bold')

# Customize the X-axis with initial and final rounded labels
plt.xticks(bin_edges, [str(int(edge)) for edge in bin_edges], fontsize=16, fontweight='bold')
plt.yticks(fontsize=16, fontweight='bold')

# Add axis labels and title (bold font)
plt.xlabel('Homolumogap', fontsize=18, fontweight='bold')
plt.ylabel('Number of Molecules', fontsize=18, fontweight='bold')
#plt.title('Distribution of Molecules by Homolumogap', fontsize=18, fontweight='bold')

# Save the plot as a file (e.g., PNG)
output_path = f'{fd}/homolumogap_histogram.png'  # Change the filename and extension as needed
plt.savefig(output_path, format='png', dpi=300, bbox_inches='tight')  # Save with high quality

# Show the plot
#plt.tight_layout()
#plt.show()

# Notify where the file is saved
print(f"Plot saved as {output_path}")

# generate the descriptor using RdKit

def RDkit_descriptors(smiles):
    mols = [Chem.MolFromSmiles(i) for i in smiles]
    calc = MoleculeDescriptors.MolecularDescriptorCalculator([x[0]
                                    for x in Descriptors._descList])
    desc_names = calc.GetDescriptorNames()

    Mol_descriptors =[]
    for mol in mols:
        # add hydrogens to molecules
        mol=Chem.AddHs(mol)
        # Calculate all 200 descriptors for each molecule
        descriptors = calc.CalcDescriptors(mol)
        Mol_descriptors.append(descriptors)
    return Mol_descriptors,desc_names

# Function call
Mol_descriptors,desc_names = RDkit_descriptors(new_data['smiles'])

# now our features are as follows

df_descriptor = pd.DataFrame(Mol_descriptors,columns=desc_names)

df_descriptor

"""# Feature Engineering and pre-processing"""

def remove_correlated_features(descriptors):
    # Calculate correlation
    correlated_matrix = descriptors.corr().abs()

    # Upper triangle of correlation matrix
    upper_triangle = correlated_matrix.where(np.triu(np.ones(correlated_matrix.shape),k=1).astype(bool))

    # Identify columns that have above 0.9 values of correlation
    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] >= 0.90)]
    print(to_drop)
    descriptors_correlated_dropped = descriptors.drop(columns=to_drop, axis=1)
    return descriptors_correlated_dropped

aev_new = remove_correlated_features(df_descriptor)
#aev_new

X=aev_new
y=new_data.homolumogap

#DATA_Splitting

from sklearn.model_selection import train_test_split

# Assuming X and y are your features and target arrays
# Split dataset into 80% train and 20% rest (validation + test)
X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=0.20, random_state=42)

# Split the rest into 5% validation and 15% test
X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.75, random_state=42)

X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test

"""# Catboost Regressor"""

from catboost import CatBoostRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

import pandas as pd
import matplotlib.pyplot as plt
from catboost import CatBoostRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split


# Initialize the CatBoostRegressor with the best hyperparameters
final_model_CatB = CatBoostRegressor(
    iterations=1600,
    depth=10,
    learning_rate=0.08003866739082473,
    l2_leaf_reg=1.2219300331335978,
    bagging_temperature=0.9026337873010564,
    cat_features=[],  # Specify categorical features by their indices if any
    random_seed=42,
    verbose=100,  # Log progress every 100 iterations
    # Include eval_metric for both training and evaluation
    eval_metric='MAE',
    loss_function='RMSE'
)

# Train the model with validation set
final_model_CatB.fit(
    X_train,
    y_train,
    eval_set=(X_val, y_val),  # Validation data for monitoring
    early_stopping_rounds=100,  # Stop training if no improvement for 100 iterations
    use_best_model=True        # Retain the best model during training
)

# Retrieve training and validation losses
evals_result = final_model_CatB.get_evals_result()

# Extract training and validation losses
train_loss = evals_result['learn']['RMSE']  # 'MAE' for training loss
val_loss = evals_result['validation']['RMSE']  # 'MAE' for validation loss

# Save the losses to a CSV file
loss_df = pd.DataFrame({
    'Iteration': range(1, len(train_loss) + 1),
    'Training Loss': train_loss,
    'Validation Loss': val_loss
})

loss_df.to_csv(f'{fd}/catboost_train_validation_losses.csv', index=False)

# Plot the training and validation losses
import pandas as pd
import matplotlib.pyplot as plt

# Load the losses from the CSV file
loss_df = pd.read_csv(f'{fd}/catboost_train_validation_losses.csv')

# Plot the training and validation losses
plt.figure(figsize=(10, 6))
plt.plot(loss_df['Iteration'], loss_df['Training Loss'], label='Training Loss', color='blue')
plt.plot(loss_df['Iteration'], loss_df['Validation Loss'], label='Validation Loss', color='red')
plt.xlabel('Iterations',fontsize=22, fontweight='bold')
plt.ylabel('Loss (eV)', fontsize=22, fontweight='bold')
plt.xticks(fontsize=20, fontweight='bold')
plt.yticks(fontsize=20, fontweight='bold')
#plt.title(f'{fd}/catboost_train_validation_losses.csv')
plt.legend()
plt.grid(True)
plt.savefig(f'{fd}/catboost_model_train_validation_losses.png', dpi=300, bbox_inches='tight')
#plt.show()

# save the trained model weight
final_model_CatB.save_model(f'{fd}/CatBoost_model.weights.h5')

#load saved model
final_model_CatB.load_model(f'{fd}/CatBoost_model.weights.h5')

# Predict on the testing data
predictions_val_catB = final_model_CatB.predict(X_val)
predictions_test_catB = final_model_CatB.predict(X_test)
predictions_train_catB = final_model_CatB.predict(X_train)

# Calculate MAE
mae_test_catB = mean_absolute_error(y_test, predictions_test_catB)
mae_val_catB = mean_absolute_error(y_val, predictions_val_catB)
mae_train_catB = mean_absolute_error(y_train, predictions_train_catB)
print("Mean Absolute Error:", mae_test_catB)
print("Mean Absolute Error:", mae_val_catB)
print("Mean Absolute Error:", mae_train_catB)

# R^2 (coefficient of determination) regression score function:
R2_test_catB =r2_score(y_test, predictions_test_catB)
R2_val_catB =r2_score(y_val, predictions_val_catB)
R2_train_catB =r2_score(y_train, predictions_train_catB)
print('R^2:', R2_test_catB)
print('R^2:', R2_val_catB)
print('R^2:', R2_train_catB)


#MSE
from sklearn.metrics import mean_squared_error
mse_test_catB = mean_squared_error(y_test, predictions_test_catB)
mse_val_catB = mean_squared_error(y_val, predictions_val_catB)
mse_train_catB = mean_squared_error(y_train, predictions_train_catB)
print('MSE:', mse_test_catB)
print('MSE:', mse_val_catB)
print('MSE:', mse_train_catB)

#RMSE
from sklearn.metrics import mean_squared_error
rmse_test_catB = mean_squared_error(y_test, predictions_test_catB)
rmse_val_catB = mean_squared_error(y_val, predictions_val_catB)
rmse_train_catB = mean_squared_error(y_train, predictions_train_catB)
print('RMSE:', rmse_test_catB)
print('RMSE:', rmse_val_catB)
print('RMSE:', rmse_train_catB)

#Save the metrics in a csv file
import pandas as pd
df_test = pd.DataFrame({'MAE': [mae_test_catB], 'R2': [R2_test_catB], 'MSE': [mse_test_catB], 'RMSE': [rmse_test_catB]})
df_val = pd.DataFrame({'MAE': [mae_val_catB], 'R2': [R2_val_catB], 'MSE': [mse_val_catB], 'RMSE': [rmse_val_catB]})
df_train = pd.DataFrame({'MAE': [mae_train_catB], 'R2': [R2_train_catB], 'MSE': [mse_train_catB], 'RMSE': [rmse_train_catB]})


#Save df in csv file
df_test.to_csv(f'{fd}/CatB_model_test_metrics.csv', index=False)
df_val.to_csv(f'{fd}/CatB_model_val_metrics.csv', index=False)
df_train.to_csv(f'{fd}/CatB_model_train_metrics.csv', index=False)

import pandas as pd

# Create DataFrame for actual vs predicted values for test set
df_test_predictions = pd.DataFrame({
    'Actual': y_test,  # Actual values
    'Predicted': predictions_test_catB  # Predicted values
})

# Create DataFrame for actual vs predicted values for val set
df_val_predictions = pd.DataFrame({
    'Actual': y_val,  # Actual values
    'Predicted': predictions_val_catB  # Predicted values
})

# Create DataFrame for actual vs predicted values for train set
df_train_predictions = pd.DataFrame({
    'Actual': y_train,  # Actual values
    'Predicted': predictions_train_catB  # Predicted values
})


# Save the DataFrames to CSV
df_test_predictions.to_csv(f'{fd}/CatB_model_test_actual_vs_predicted.csv', index=False)
df_val_predictions.to_csv(f'{fd}/CatB_model_val_actual_vs_predicted.csv', index=False)
df_train_predictions.to_csv(f'{fd}/CatB_model_train_actual_vs_predicted.csv', index=False)

print("CSV files saved successfully!")

#load the csv file
test_plot=pd.read_csv(f'{fd}/CatB_model_test_actual_vs_predicted.csv')
val_plot = pd.read_csv(f'{fd}/CatB_model_val_actual_vs_predicted.csv')
train_plot = pd.read_csv(f'{fd}/CatB_model_train_actual_vs_predicted.csv')

#load the csv file
test_plot=pd.read_csv(f'{fd}/CatB_model_test_actual_vs_predicted.csv')

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import linregress
import matplotlib.colors as colors
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

actual = test_plot['Actual']
predicted = test_plot['Predicted']

# Calculate MAE, RMSE, and R^2
mae = mean_absolute_error(actual, predicted)
rmse = np.sqrt(mean_squared_error(actual, predicted))
r2 = r2_score(actual, predicted)


fig, ax = plt.subplots(figsize=(10, 6))

hb1 = ax.hist2d(actual, predicted, bins=150, norm=colors.LogNorm(), cmap='plasma')
ax.plot([actual.min(), actual.max()], [actual.min(), actual.max()],
        color='red', linestyle='--', label='Ideal Prediction')
ax.set_xlabel('Actual Value', fontsize=22, fontweight='bold')
ax.set_ylabel('Predicted Value', fontsize=22, fontweight='bold')

plt.xticks(fontsize=18, fontweight='bold')
plt.yticks(fontsize=18, fontweight='bold')

#ax.set_title('Actual vs. Predicted Values', fontsize=16
#ax.text(0.05, 1.05, '(a)', transform=ax.transAxes, fontsize=18, fontweight='bold')

slope, intercept, r_value, _, _ = linregress(actual, predicted)
ax.text(0.05, 0.85, f'Slope = {slope:.4f}\nIntercept = {intercept:.4f}', transform=ax.transAxes,
        fontsize=16, bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))


ax.text(0.60, 0.1, f'MAE = {mae:.4f} eV', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))
ax.text(0.60, 0.2, f'RMSE = {rmse:.4f} eV', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))
ax.text(0.60, 0.3, f'$R^2$ = {r2:.4f}', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))

cb = plt.colorbar(hb1[3], ax=ax, label='Count')
cb.ax.tick_params(labelsize=14)  # Adjust the font size of the colorbar ticks
cb.set_label('Count', fontsize=18, fontweight='bold')  # Adjust the font size of the colorbar label

plt.savefig(f'{fd}/catB_actual_vs_predicted_test.png', dpi=300, bbox_inches='tight')
plt.show()

"""# Optimized LGBMRegressor"""

# Initialize the scaler
scaler = StandardScaler()

# Fit and transform the training data
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

import pandas as pd
import matplotlib.pyplot as plt
from lightgbm import LGBMRegressor
import lightgbm as lgb
from sklearn.preprocessing import StandardScaler
import os

# Assuming X_train, X_val, X_test, y_train, y_val, y_test are already defined

# Scale the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Initialize the LightGBM model
lgbm_model = LGBMRegressor(
    force_col_wise=True,
    learning_rate=0.03,
    num_leaves=125,
    max_depth=20,
    min_child_samples=15,
    subsample=1.0,
    colsample_bytree=0.7,
    n_estimators=4000,
    reg_alpha=0.1,
    reg_lambda=0.1,
    random_state=42,
    verbose=100
)

# Train the model with RMSE as the evaluation metric
lgbm_model.fit(
    X_train_scaled,
    y_train,
    eval_set=[(X_train_scaled, y_train), (X_val_scaled, y_val)],
    eval_metric='rmse',  # Set RMSE as the evaluation metric
    callbacks=[lgb.early_stopping(stopping_rounds=200)]
)

# Retrieve training and validation losses
evals_result = lgbm_model.evals_result_

# Extract RMSE losses
train_loss = evals_result['training']['rmse']
val_loss = evals_result['valid_1']['rmse']

# Save the losses to a CSV file
loss_df = pd.DataFrame({
    'Iteration': range(1, len(train_loss) + 1),
    'Training RMSE': train_loss,
    'Validation RMSE': val_loss
})

loss_df.to_csv(f'{fd}/lgbm_train_validation_losses.csv', index=False)

pd1=pd.read_csv(f'{fd}/lgbm_train_validation_losses.csv')
pd1

# Plot the training and validation losses
import pandas as pd
import matplotlib.pyplot as plt

# Load the losses from the CSV file
loss_df = pd.read_csv(f'{fd}/lgbm_train_validation_losses.csv')

# Plot the training and validation losses
plt.figure(figsize=(10, 6))
plt.plot(loss_df['Iteration'], loss_df['Training RMSE'], label='Training Loss', color='blue')
plt.plot(loss_df['Iteration'], loss_df['Validation RMSE'], label='Validation Loss', color='red')
plt.xlabel('Iteration',fontsize=22, fontweight='bold')
plt.ylabel('Loss (eV)', fontsize=22, fontweight='bold')
plt.xticks(fontsize=18, fontweight='bold')
plt.yticks(fontsize=18, fontweight='bold')

#plt.title(f'{fd}/lgbm_train_validation_losses.csv', fontsize=18, fontweight='bold')
plt.legend()
plt.grid(True)
plt.savefig(f'{fd}/lgbm_model_train_validation_losses.png', dpi=300, bbox_inches='tight')
plt.show()

#save trained lgbm model so that I can load it latter
import pickle
filename = f'{fd}/LGBM_model_weights.txt'
pickle.dump(lgbm_model, open(filename, 'wb'))

#load saved model
import pickle
filename = f'{fd}/LGBM_model_weights.txt'
lgbm_model = pickle.load(open(filename, 'rb'))

# Predict on the testing data
predictions_val_lgbm = lgbm_model.predict(X_val_scaled)
predictions_test_lgbm = lgbm_model.predict(X_test_scaled)
predictions_train_lgbm = lgbm_model.predict(X_train_scaled)

# Calculate MAE
mae_test_lgbm = mean_absolute_error(y_test, predictions_test_lgbm)
mae_val_lgbm = mean_absolute_error(y_val, predictions_val_lgbm)
mae_train_lgbm = mean_absolute_error(y_train, predictions_train_lgbm)
print("Mean Absolute Error:", mae_test_lgbm)
print("Mean Absolute Error:", mae_val_lgbm)
print("Mean Absolute Error:", mae_train_lgbm)

# R^2 (coefficient of determination) regression score function:
R2_test =r2_score(y_test, predictions_test_lgbm)
R2_val =r2_score(y_val, predictions_val_lgbm)
R2_train =r2_score(y_train, predictions_train_lgbm)
print('R^2:', R2_test)
print('R^2:', R2_val)
print('R^2:', R2_train)

#MSE
from sklearn.metrics import mean_squared_error
mse_test = mean_squared_error(y_test, predictions_test_lgbm)
mse_val = mean_squared_error(y_val, predictions_val_lgbm)
mse_train = mean_squared_error(y_train, predictions_train_lgbm)
print('MSE:', mse_test)
print('MSE:', mse_val)
print('MSE:', mse_train)

#RMSE
rmse_test = mean_squared_error(y_test, predictions_test_lgbm)
rmse_val = mean_squared_error(y_val, predictions_val_lgbm)
rmse_train = mean_squared_error(y_train, predictions_train_lgbm)
print('RMSE:', rmse_test)

#Save the metrics in a csv file
import pandas as pd
df_test = pd.DataFrame({'MAE': [mae_test_lgbm], 'R2': [R2_test], 'MSE': [mse_test], 'RMSE': [rmse_test]})
df_val = pd.DataFrame({'MAE': [mae_val_lgbm], 'R2': [R2_val], 'MSE': [mse_val], 'RMSE': [rmse_val]})
df_train = pd.DataFrame({'MAE': [mae_train_lgbm], 'R2': [R2_train], 'MSE': [mse_train], 'RMSE': [rmse_train]})
#Save df in csv file
df_test.to_csv(f'{fd}/LGBM_model_test_metrics.csv', index=False)
df_val.to_csv(f'{fd}/LGBM_model_val_metrics.csv', index=False)
df_train.to_csv(f'{fd}/LGBM_model_train_metrics.csv', index=False)

import pandas as pd

# Create DataFrame for actual vs predicted values for test set
df_test_predictions = pd.DataFrame({
    'Actual': y_test,  # Actual values
    'Predicted': predictions_test_lgbm  # Predicted values
})
df_val_predictions = pd.DataFrame({
    'Actual': y_val,  # Actual values
    'Predicted': predictions_val_lgbm  # Predicted values
})
df_train_predictions = pd.DataFrame({
    'Actual': y_train,  # Actual values
    'Predicted': predictions_train_lgbm  # Predicted values
})


# Save the DataFrames to CSV
df_test_predictions.to_csv(f'{fd}/lgbm_test_actual_vs_predicted.csv', index=False)
df_val_predictions.to_csv(f'{fd}/lgbm_val_actual_vs_predicted.csv', index=False)
df_train_predictions.to_csv(f'{fd}/lgbm_train_actual_vs_predicted.csv', index=False)

print("CSV files saved successfully!")

#load the csv file
lgbmR_plot=pd.read_csv(f'{fd}/lgbm_test_actual_vs_predicted.csv')
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import linregress
import matplotlib.colors as colors
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

actual = lgbmR_plot['Actual']
predicted = lgbmR_plot['Predicted']

# Calculate MAE, RMSE, and R^2
mae = mean_absolute_error(actual, predicted)
rmse = np.sqrt(mean_squared_error(actual, predicted))
r2 = r2_score(actual, predicted)


fig, ax = plt.subplots(figsize=(10, 6))

hb1 = ax.hist2d(actual, predicted, bins=150, norm=colors.LogNorm(), cmap='plasma')
ax.plot([actual.min(), actual.max()], [actual.min(), actual.max()],
        color='red', linestyle='--', label='Ideal Prediction')
ax.set_xlabel('Actual Value', fontsize=22, fontweight='bold')
ax.set_ylabel('Predicted Value', fontsize=22, fontweight='bold')

plt.xticks(fontsize=18, fontweight='bold')
plt.yticks(fontsize=18, fontweight='bold')

#ax.set_title('Actual vs. Predicted Values', fontsize=16
#ax.text(0.05, 1.05, '(a)', transform=ax.transAxes, fontsize=18, fontweight='bold')

slope, intercept, r_value, _, _ = linregress(actual, predicted)
ax.text(0.05, 0.85, f'Slope = {slope:.4f}\nIntercept = {intercept:.4f}', transform=ax.transAxes,
        fontsize=16, bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))


ax.text(0.60, 0.1, f'MAE = {mae:.4f} eV', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))
ax.text(0.60, 0.2, f'RMSE = {rmse:.4f} eV', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))
ax.text(0.60, 0.3, f'$R^2$ = {r2:.4f}', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))

cb = plt.colorbar(hb1[3], ax=ax, label='Count')
cb.ax.tick_params(labelsize=14)  # Adjust the font size of the colorbar ticks
cb.set_label('Count', fontsize=16, fontweight='bold')  # Adjust the font size of the colorbar label

plt.savefig(f'{fd}/lgbmR_actual_vs_predicted_test.png', dpi=300, bbox_inches='tight')
plt.show()

"""# Bidirectional LSTM"""

X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])
X_val_reshaped = X_val_scaled.reshape(X_val_scaled.shape[0], 1, X_val_scaled.shape[1])
X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])

X_test_reshaped.shape

import numpy as np
import pandas as pd
import tensorflow as tf
import random
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Bidirectional
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import StandardScaler

# Set random seed for reproducibility
seed_value = 42
np.random.seed(seed_value)
random.seed(seed_value)
tf.random.set_seed(seed_value)

# Scale the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Reshape the data for LSTM (3D input: samples, timesteps, features)
X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_val_reshaped = np.reshape(X_val_scaled, (X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))
X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

# Define the BiLSTM model
Bilstm_model = Sequential([
    Bidirectional(LSTM(units=64, activation='relu', return_sequences=True), input_shape=(1, X_train.shape[1])),
    Bidirectional(LSTM(units=64, activation='relu', return_sequences=True)),
    Bidirectional(LSTM(units=64, activation='relu', return_sequences=True)),
    Bidirectional(LSTM(units=64, activation='relu', return_sequences=True)),
    Bidirectional(LSTM(units=64, activation='relu')),
    Dense(units=1)  # Output layer for regression
])

# Define a custom RMSE loss function
def root_mean_squared_error(y_true, y_pred):
    mse = tf.keras.losses.MeanSquaredError()
    return tf.sqrt(mse(y_true, y_pred))

# Compile the model with the custom RMSE loss function
Bilstm_model.compile(optimizer='adam', loss=root_mean_squared_error)

# Early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = Bilstm_model.fit(
    X_train_reshaped, y_train,
    validation_data=(X_val_reshaped, y_val),
    epochs=100,
    batch_size=128,
    verbose=1,
    callbacks=[early_stopping]
)

# Extract RMSE losses
training_loss = history.history['loss']
validation_loss = history.history['val_loss']

loss_df = pd.DataFrame({
    'Epoch': range(1, len(training_loss) + 1),
    'Training RMSE': training_loss,
    'Validation RMSE': validation_loss
})

loss_df.to_csv(f'{fd}/bilstm_train_validation_losses.csv', index=False)

# Plotting the training and validation loss
import pandas as pd
import matplotlib.pyplot as plt

# Load the losses from the CSV file
loss_df = pd.read_csv(f'{fd}/bilstm_train_validation_losses.csv')
# Plot training and validation loss
plt.figure(figsize=(10, 6))
plt.plot(loss_df['Epoch'], loss_df['Training RMSE'], label='Training Loss')
plt.plot(loss_df['Epoch'], loss_df['Validation RMSE'], label='Validation Loss')
plt.xlabel('Epochs',fontsize=22, fontweight='bold')
plt.ylabel('Loss (eV)', fontsize=22, fontweight='bold')
plt.xticks(fontsize=18, fontweight='bold')
plt.yticks(fontsize=18, fontweight='bold')
#plt.title('Training and Validation Loss')
plt.legend()
plt.grid(True)
plt.show()
plt.savefig(f'{fd}/bilstm_model_train_validation_losses.png', dpi=300, bbox_inches='tight')
#plt.show()

#save the model weight
Bilstm_model.save_weights(f'{fd}/Bi_LSTM_model.weights.h5')

#load the saved model
Bilstm_model.load_weights(f'{fd}/Bi_LSTM_model.weights.h5')

# Predict on the testing data
predictions_test_Bilstm = Bilstm_model.predict(X_test_reshaped)
predictions_val_Bilstm = Bilstm_model.predict(X_val_reshaped)
predictions_train_Bilstm = Bilstm_model.predict(X_train_reshaped)

# Calculate MAE
mae_test = mean_absolute_error(y_test, predictions_test_Bilstm)
mae_val = mean_absolute_error(y_val, predictions_val_Bilstm)
mae_train = mean_absolute_error(y_train, predictions_train_Bilstm)
print("Mean Absolute Error:", mae_test)
print("Mean Absolute Error:", mae_val)
print("Mean Absolute Error:", mae_train)

# R^2 (coefficient of determination) regression score function:
R2_test =r2_score(y_test, predictions_test_Bilstm)
R2_val =r2_score(y_val, predictions_val_Bilstm)
R2_train =r2_score(y_train, predictions_train_Bilstm)
print('R^2:', R2_test)
print('R^2:', R2_val)
print('R^2:', R2_train)

#MSE
from sklearn.metrics import mean_squared_error
mse_test = mean_squared_error(y_test, predictions_test_Bilstm)
mse_val = mean_squared_error(y_val, predictions_val_Bilstm)
mse_train = mean_squared_error(y_train, predictions_train_Bilstm)
print('MSE:', mse_test)
print('MSE:', mse_val)
print('MSE:', mse_train)

#RMSE
rmse_test = mean_squared_error(y_test, predictions_test_Bilstm)
rmse_val = mean_squared_error(y_val, predictions_val_Bilstm)
rmse_train = mean_squared_error(y_train, predictions_train_Bilstm)
print('RMSE:', rmse_test)

#Save the metrics in a csv file
import pandas as pd
df_test = pd.DataFrame({'MAE': [mae_test], 'R2': [R2_test], 'MSE': [mse_test], 'RMSE': [rmse_test]})
df_val = pd.DataFrame({'MAE': [mae_val], 'R2': [R2_val], 'MSE': [mse_val], 'RMSE': [rmse_val]})
df_train = pd.DataFrame({'MAE': [mae_train], 'R2': [R2_train], 'MSE': [mse_train], 'RMSE': [rmse_train]})
#Save df in csv file
df_test.to_csv(f'{fd}/Bilstm_model_test_metrics.csv', index=False)
df_val.to_csv(f'{fd}/Bilstm_model_val_metrics.csv', index=False)
df_train.to_csv(f'{fd}/Bilstm_model_train_metrics.csv', index=False)

import pandas as pd

# Create DataFrame for actual vs predicted values for test set
df_test_predictions = pd.DataFrame({
    'Actual': y_test,  # Actual values
    'Predicted': predictions_test_Bilstm.flatten()   # Predicted values
})
df_val_predictions = pd.DataFrame({
    'Actual': y_val,  # Actual values
    'Predicted': predictions_val_Bilstm.flatten()   # Predicted values
})
df_train_predictions = pd.DataFrame({
    'Actual': y_train,  # Actual values
    'Predicted': predictions_train_Bilstm.flatten()   # Predicted values
})

# Save the DataFrames to CSV
df_test_predictions.to_csv(f'{fd}/Bilstm_test_actual_vs_predicted.csv', index=False)
df_val_predictions.to_csv(f'{fd}/Bilstm_val_actual_vs_predicted.csv', index=False)
df_train_predictions.to_csv(f'{fd}/Bilstm_train_actual_vs_predicted.csv', index=False)

print("CSV files saved successfully!")

#load the csv file
Bilstm_plot=pd.read_csv(f'{fd}/Bilstm_test_actual_vs_predicted.csv')

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import linregress
import matplotlib.colors as colors
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

actual = Bilstm_plot['Actual']
predicted = Bilstm_plot['Predicted']

# Calculate MAE, RMSE, and R^2
mae = mean_absolute_error(actual, predicted)
rmse = np.sqrt(mean_squared_error(actual, predicted))
r2 = r2_score(actual, predicted)


fig, ax = plt.subplots(figsize=(10, 6))

hb1 = ax.hist2d(actual, predicted, bins=150, norm=colors.LogNorm(), cmap='plasma')
ax.plot([actual.min(), actual.max()], [actual.min(), actual.max()],
        color='red', linestyle='--', label='Ideal Prediction')
ax.set_xlabel('Actual Value', fontsize=22, fontweight='bold')
ax.set_ylabel('Predicted Value', fontsize=22, fontweight='bold')

plt.xticks(fontsize=18, fontweight='bold')
plt.yticks(fontsize=18, fontweight='bold')

#ax.set_title('Actual vs. Predicted Values', fontsize=16
#ax.text(0.05, 1.05, '(a)', transform=ax.transAxes, fontsize=18, fontweight='bold')

slope, intercept, r_value, _, _ = linregress(actual, predicted)
ax.text(0.05, 0.85, f'Slope = {slope:.4f}\nIntercept = {intercept:.4f}', transform=ax.transAxes,
        fontsize=16, bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))


ax.text(0.60, 0.1, f'MAE = {mae:.4f} eV', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))
ax.text(0.60, 0.2, f'RMSE = {rmse:.4f} eV', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))
ax.text(0.60, 0.3, f'$R^2$ = {r2:.4f}', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))

cb = plt.colorbar(hb1[3], ax=ax, label='Count')
cb.ax.tick_params(labelsize=14)  # Adjust the font size of the colorbar ticks
cb.set_label('Count', fontsize=16, fontweight='bold')  # Adjust the font size of the colorbar label

plt.savefig(f'{fd}/Bilstm_actual_vs_predicted_test.png', dpi=300, bbox_inches='tight')
#plt.show()

"""# Multilayer Perceptron (MLP)"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
import os

# Assuming X_train, X_val, X_test, y_train, y_val, y_test are already defined

# Scale the data (train, validation, and test)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Initialize the MLPRegressor
mlp1 = MLPRegressor(
    hidden_layer_sizes=(500, 100, 50),
    max_iter=1000,
    activation='relu',
    solver='adam',
    random_state=42,
    learning_rate='adaptive',
    learning_rate_init=0.001,
    warm_start=True
)

# Initialize lists to store losses
train_losses = []
val_losses = []
epochs = []

# Early stopping parameters
patience = 50
best_val_loss = float('inf')
epochs_without_improvement = 0

# Train the model with manual epoch loop
for epoch in range(100):  # You can set a higher number of epochs
    mlp1.fit(X_train_scaled, y_train)

    # Compute RMSE for training loss
    train_loss = np.sqrt(mlp1.loss_)  # Convert MLP loss to RMSE
    train_losses.append(train_loss)

    # Compute RMSE for validation loss
    val_pred = mlp1.predict(X_val_scaled)
    val_loss = np.sqrt(mean_squared_error(y_val, val_pred))
    val_losses.append(val_loss)

    # Store epoch number
    epochs.append(epoch + 1)

    print(f"Epoch {epoch + 1} - Training RMSE: {train_loss:.4f}, Validation RMSE: {val_loss:.4f}")

    # Early stopping
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        epochs_without_improvement = 0
    else:
        epochs_without_improvement += 1

    if epochs_without_improvement >= patience:
        print(f"Early stopping at epoch {epoch + 1} due to no improvement in validation loss.")
        break

# Save RMSE losses to CSV
loss_df = pd.DataFrame({
    'Epoch': epochs,
    'Training RMSE': train_losses,
    'Validation RMSE': val_losses
})

# Save the DataFrame to CSV
loss_df.to_csv(f'{fd}/train_validation_losses.csv', index=False)

# Plotting the training and validation loss
plt.figure(figsize=(10, 6))
plt.plot(loss_df['Epoch'], loss_df['Training RMSE'], label='Training Loss', color='blue')
plt.plot(loss_df['Epoch'], loss_df['Validation RMSE'], label='Validation Loss', color='red')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss per Epoch')
plt.legend()
plt.grid(True)
plt.show()

import pickle

# Save the entire model using pickle
with open(f'{fd}/mlp1_model.pkl', 'wb') as file:
    pickle.dump(mlp1, file)

#Load the saved model
with open(f'{fd}/mlp1_model.pkl', 'rb') as file:
    mlp1 = pickle.load(file)

# Predict on the testing data
predictions_test_mlp1 = mlp1.predict(X_test_scaled)
predictions_val_mlp1 = mlp1.predict(X_val_scaled)
predictions_train_mlp1 = mlp1.predict(X_train_scaled)

# Calculate MAE
mae_test = mean_absolute_error(y_test, predictions_test_mlp1)
mae_val = mean_absolute_error(y_val, predictions_val_mlp1)
mae_train = mean_absolute_error(y_train, predictions_train_mlp1)
print("Mean Absolute Error:", mae_test)
print("Mean Absolute Error:", mae_val)
print("Mean Absolute Error:", mae_train)

# R^2 (coefficient of determination) regression score function:
R2_test =r2_score(y_test, predictions_test_mlp1)
R2_val =r2_score(y_val, predictions_val_mlp1)
R2_train =r2_score(y_train, predictions_train_mlp1)
print('R^2:', R2_test)
print('R^2:', R2_val)
print('R^2:', R2_train)

#MSE
from sklearn.metrics import mean_squared_error
mse_test = mean_squared_error(y_test, predictions_test_mlp1)
mse_val = mean_squared_error(y_val, predictions_val_mlp1)
mse_train = mean_squared_error(y_train, predictions_train_mlp1)
print('MSE:', mse_test)
print('MSE:', mse_val)
print('MSE:', mse_train)

#RMSE
rmse_test = mean_squared_error(y_test, predictions_test_mlp1)
rmse_val = mean_squared_error(y_val, predictions_val_mlp1)
rmse_train = mean_squared_error(y_train, predictions_train_mlp1)
print('RMSE:', rmse_test)

#Save the metrics in a csv file
import pandas as pd
df_test = pd.DataFrame({'MAE': [mae_test], 'R2': [R2_test], 'MSE': [mse_test], 'RMSE': [rmse_test]})
df_val = pd.DataFrame({'MAE': [mae_val], 'R2': [R2_val], 'MSE': [mse_val], 'RMSE': [rmse_val]})
df_train = pd.DataFrame({'MAE': [mae_train], 'R2': [R2_train], 'MSE': [mse_train], 'RMSE': [rmse_train]})
#Save df in csv file
df_test.to_csv(f'{fd}/mlp1_model_test_metrics.csv', index=False)
df_val.to_csv(f'{fd}/mlp1_model_val_metrics.csv', index=False)
df_train.to_csv(f'{fd}/mlp1_model_train_metrics.csv', index=False)

import pandas as pd

# Create DataFrame for actual vs predicted values for test set
df_test_predictions = pd.DataFrame({
    'Actual': y_test,  # Actual values
    'Predicted': predictions_test_mlp1  # Predicted values
})

df_val_predictions = pd.DataFrame({
    'Actual': y_val,  # Actual values
    'Predicted': predictions_val_mlp1  # Predicted values
})

df_train_predictions = pd.DataFrame({
    'Actual': y_train,  # Actual values
    'Predicted': predictions_train_mlp1  # Predicted values
})

# Save the DataFrames to CSV
df_test_predictions.to_csv(f'{fd}/mlp1_test_actual_vs_predicted.csv', index=False)
df_val_predictions.to_csv(f'{fd}/mlp1_val_actual_vs_predicted.csv', index=False)
df_train_predictions.to_csv(f'{fd}/mlp1_train_actual_vs_predicted.csv', index=False)

print("CSV files saved successfully!")

# Plotting the training and validation loss
loss_df = pd.read_csv(f'{fd}/train_validation_losses.csv')

plt.figure(figsize=(10, 6))
plt.plot(loss_df['Epoch'], loss_df['Training RMSE'], label='Training Loss', color='blue')
plt.plot(loss_df['Epoch'], loss_df['Validation RMSE'], label='Validation Loss', color='red')
plt.xlabel('Epochs',fontsize=22, fontweight='bold')
plt.ylabel('Loss (eV)', fontsize=22, fontweight='bold')
plt.tick_params(axis='x', labelsize=18) # Changed to plt.tick_params and specified axis
plt.tick_params(axis='y', labelsize=18)
plt.legend()
plt.grid(True)
plt.savefig(f'{fd}/mlp1_train_validation_losses.png', dpi=300, bbox_inches='tight')
#plt.show()

#load the csv file
mlp1_plot=pd.read_csv(f'{fd}/mlp1_test_actual_vs_predicted.csv')

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import linregress
import matplotlib.colors as colors
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

actual = mlp1_plot['Actual']
predicted = mlp1_plot['Predicted']

# Calculate MAE, RMSE, and R^2
mae = mean_absolute_error(actual, predicted)
rmse = np.sqrt(mean_squared_error(actual, predicted))
r2 = r2_score(actual, predicted)


fig, ax = plt.subplots(figsize=(10, 6))

hb1 = ax.hist2d(actual, predicted, bins=150, norm=colors.LogNorm(), cmap='plasma')
ax.plot([actual.min(), actual.max()], [actual.min(), actual.max()],
        color='red', linestyle='--', label='Ideal Prediction')
ax.set_xlabel('Actual Value', fontsize=22, fontweight='bold')
ax.set_ylabel('Predicted Value', fontsize=22, fontweight='bold')

plt.xticks(fontsize=18, fontweight='bold')
plt.yticks(fontsize=18, fontweight='bold')

#ax.set_title('Actual vs. Predicted Values', fontsize=16
#ax.text(0.05, 1.05, '(a)', transform=ax.transAxes, fontsize=18, fontweight='bold')

slope, intercept, r_value, _, _ = linregress(actual, predicted)
ax.text(0.05, 0.85, f'Slope = {slope:.4f}\nIntercept = {intercept:.4f}', transform=ax.transAxes,
        fontsize=16, bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))


ax.text(0.60, 0.1, f'MAE = {mae:.4f} eV', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))
ax.text(0.60, 0.2, f'RMSE = {rmse:.4f} eV', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))
ax.text(0.60, 0.3, f'$R^2$ = {r2:.4f}', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))

cb = plt.colorbar(hb1[3], ax=ax, label='Count')
cb.ax.tick_params(labelsize=14)  # Adjust the font size of the colorbar ticks
cb.set_label('Count', fontsize=16, fontweight='bold')  # Adjust the font size of the colorbar label

plt.savefig(f'{fd}/mlp1_actual_vs_predicted_test.png', dpi=300, bbox_inches='tight')
#plt.show()

"""# Ensemble of LGBMRegressor, LSTM, MLP and CatboostRegressor"""

# Generate predictions on the training, Validation and testing data
lgbm_train_preds = lgbm_model.predict(X_train_scaled)
lstm_train_preds = Bilstm_model.predict(X_train_reshaped).flatten()
mlp_train_preds = mlp1.predict(X_train_scaled)
catb_train_preds = final_model_CatB.predict(X_train)

lgbm_val_preds = lgbm_model.predict(X_val_scaled)
lstm_val_preds = Bilstm_model.predict(X_val_reshaped).flatten()
mlp_val_preds = mlp1.predict(X_val_scaled)
catb_val_preds = final_model_CatB.predict(X_val)

lgbm_test_preds = lgbm_model.predict(X_test_scaled)
lstm_test_preds = Bilstm_model.predict(X_test_reshaped).flatten()
mlp_test_preds = mlp1.predict(X_test_scaled)
catb_test_preds = final_model_CatB.predict(X_test)

import numpy as np
import pandas as pd
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt

# Define weights for each base model
lgbm_weight = 0.70
lstm_weight = 0.20
mlp_weight = 0.10
#cat_weight = 0.00

# Combine predictions with weights for training and validation
weighted_train_preds = (
    lgbm_weight * lgbm_train_preds +
    lstm_weight * lstm_train_preds +
    mlp_weight * mlp_train_preds
    #cat_weight * catb_train_preds
)

weighted_val_preds = (
    lgbm_weight * lgbm_val_preds +
    lstm_weight * lstm_val_preds +
    mlp_weight * mlp_val_preds
    #cat_weight * catb_val_preds
)

weighted_test_preds = (
    lgbm_weight * lgbm_test_preds +
    lstm_weight * lstm_test_preds +
    mlp_weight * mlp_test_preds
    #cat_weight * catb_test_preds
)

# Initialize lists to track training and validation losses
training_losses = []
validation_losses = []

# Initialize the Gradient Boosting model
esm_model = GradientBoostingRegressor(
    n_estimators=3500, learning_rate=0.01, max_depth=10, random_state=42
)

# Fit the model
esm_model.fit(weighted_train_preds.reshape(-1, 1), y_train)

# Initialize lists to store RMSE losses
training_losses = []
validation_losses = []

# Compute RMSE at each iteration using staged_predict
for i, y_pred in enumerate(esm_model.staged_predict(weighted_train_preds.reshape(-1, 1))):
    # Compute RMSE for training
    train_loss = np.sqrt(mean_squared_error(y_train, y_pred))

    # Predict on validation data using the current stage
    val_pred = esm_model.predict(weighted_val_preds.reshape(-1, 1))
    val_loss = np.sqrt(mean_squared_error(y_val, val_pred))

    # Save the RMSE losses
    training_losses.append(train_loss)
    validation_losses.append(val_loss)

# Create results directory
#output_dir = "./results"
#os.makedirs(output_dir, exist_ok=True)

# Save losses to CSV
loss_df = pd.DataFrame({
    'Iteration': range(1, len(training_losses) + 1),
    'Training RMSE': training_losses,
    'Validation RMSE': validation_losses
})

# Save losses to a CSV file
loss_df = pd.DataFrame({
    'Iteration': range(1, len(training_losses) + 1),
    'Training Loss': training_losses,
    'Validation Loss': validation_losses
})
loss_df.to_csv(f'{fd}/esm_model_train_validation_losses.csv', index=False)

# Plotting the training and validation loss
loss_df = pd.read_csv(f'{fd}/esm_model_train_validation_losses.csv')
plt.figure(figsize=(10, 6))
plt.plot(loss_df['Iteration'], loss_df['Training Loss'], label='Training Loss')
plt.plot(loss_df['Iteration'], loss_df['Validation Loss'], label='Validation Loss')
plt.xlabel('Iteration',fontsize=22, fontweight='bold')
plt.ylabel('Loss (eV)',fontsize=22, fontweight='bold')
plt.tick_params(axis='x', labelsize=18) # Changed to plt.tick_params and specified axis
plt.tick_params(axis='y', labelsize=18)
plt.legend()
plt.grid(True)
plt.savefig(f'{fd}/esm_model_train_validation_losses.png', dpi=300, bbox_inches='tight')
#plt.show()

pred_test_esm = esm_model.predict(weighted_test_preds.reshape(-1, 1))
pred_val_esm = esm_model.predict(weighted_val_preds.reshape(-1, 1))
pred_train_esm = esm_model.predict(weighted_train_preds.reshape(-1, 1))

# Calculate MAE
mae_test = mean_absolute_error(y_test, pred_test_esm)
mae_val = mean_absolute_error(y_val, pred_val_esm)
mae_train = mean_absolute_error(y_train, pred_train_esm)
print("Mean Absolute Error:", mae_test)
print("Mean Absolute Error:", mae_val)
print("Mean Absolute Error:", mae_train)

# R^2 (coefficient of determination) regression score function:
R2_test =r2_score(y_test, pred_test_esm)
R2_val =r2_score(y_val, pred_val_esm)
R2_train =r2_score(y_train, pred_train_esm)
print('R^2:', R2_test)
print('R^2:', R2_val)
print('R^2:', R2_train)

#MSE
from sklearn.metrics import mean_squared_error
mse_test = mean_squared_error(y_test, pred_test_esm)
mse_val = mean_squared_error(y_val, pred_val_esm)
mse_train = mean_squared_error(y_train, pred_train_esm)
print('MSE:', mse_test)
print('MSE:', mse_val)
print('MSE:', mse_train)

#RMSE
rmse_test = mean_squared_error(y_test, pred_test_esm)
rmse_val = mean_squared_error(y_val, pred_val_esm)
rmse_train = mean_squared_error(y_train, pred_train_esm)

#Save the metrics in a csv file
import pandas as pd
df_test = pd.DataFrame({'MAE': [mae_test], 'R2': [R2_test], 'MSE': [mse_test], 'RMSE': [rmse_test]})
df_val = pd.DataFrame({'MAE': [mae_val], 'R2': [R2_val], 'MSE': [mse_val], 'RMSE': [rmse_val]})
df_train = pd.DataFrame({'MAE': [mae_train], 'R2': [R2_train], 'MSE': [mse_train], 'RMSE': [rmse_train]})

#Save df in csv file
df_test.to_csv(f'{fd}/esm_model_test_metrics.csv', index=False)
df_val.to_csv(f'{fd}/esm_model_val_metrics.csv', index=False)
df_train.to_csv(f'{fd}/esm_model_train_metrics.csv', index=False)

import pandas as pd

# Create DataFrame for actual vs predicted values for test set
df_test_predictions = pd.DataFrame({
    'Actual': y_test,  # Actual values
    'Predicted': pred_test_esm  # Predicted values
})

# Create DataFrame for actual vs predicted values for validation set
df_val_predictions = pd.DataFrame({
    'Actual': y_val,  # Actual values
    'Predicted': pred_val_esm  # Predicted values
})
df_train_predictions = pd.DataFrame({
    'Actual': y_train,  # Actual values
    'Predicted': pred_train_esm  # Predicted values
})

# Save the DataFrames to CSV
df_test_predictions.to_csv(f'{fd}/esm_test_actual_vs_predicted.csv', index=False)
df_val_predictions.to_csv(f'{fd}/esm_val_actual_vs_predicted.csv', index=False)
df_train_predictions.to_csv(f'{fd}/esm_train_actual_vs_predicted.csv', index=False)

print("CSV files saved successfully!")

#load the csv file
esm_plot=pd.read_csv(f'{fd}/esm_test_actual_vs_predicted.csv')

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import linregress
import matplotlib.colors as colors
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

actual = esm_plot['Actual']
predicted = esm_plot['Predicted']

# Calculate MAE, RMSE, and R^2
mae = mean_absolute_error(actual, predicted)
rmse = np.sqrt(mean_squared_error(actual, predicted))
r2 = r2_score(actual, predicted)


fig, ax = plt.subplots(figsize=(10, 6))

hb1 = ax.hist2d(actual, predicted, bins=150, norm=colors.LogNorm(), cmap='plasma')
ax.plot([actual.min(), actual.max()], [actual.min(), actual.max()],
        color='red', linestyle='--', label='Ideal Prediction')
ax.set_xlabel('Actual Value', fontsize=18, fontweight='bold')
ax.set_ylabel('Predicted Value', fontsize=18, fontweight='bold')

plt.xticks(fontsize=16, fontweight='bold')
plt.yticks(fontsize=16, fontweight='bold')

#ax.set_title('Actual vs. Predicted Values', fontsize=16
#ax.text(0.05, 1.05, '(a)', transform=ax.transAxes, fontsize=18, fontweight='bold')

slope, intercept, r_value, _, _ = linregress(actual, predicted)
ax.text(0.05, 0.85, f'Slope = {slope:.4f}\nIntercept = {intercept:.4f}', transform=ax.transAxes,
        fontsize=16, bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))


ax.text(0.60, 0.1, f'MAE = {mae:.4f} eV', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))
ax.text(0.60, 0.2, f'RMSE = {rmse:.4f} eV', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))
ax.text(0.60, 0.3, f'$R^2$ = {r2:.4f}', transform=ax.transAxes,
        fontsize=16, verticalalignment='top', fontweight='bold', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))

cb = plt.colorbar(hb1[3], ax=ax, label='Count')
cb.ax.tick_params(labelsize=14)  # Adjust the font size of the colorbar ticks
cb.set_label('Count', fontsize=16, fontweight='bold')  # Adjust the font size of the colorbar label

plt.savefig(f'{fd}/esm_actual_vs_predicted_test.png', dpi=300, bbox_inches='tight')
#plt.show()